{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last ned datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversikt over attributtene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversikt over klassene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tren en klassifiseringsmodell på datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(X))\n",
    "number_of_training_examples = int(0.8*len(X))\n",
    "\n",
    "X_train=X[indices[:number_of_training_examples]]\n",
    "Y_train=Y[indices[:number_of_training_examples]]\n",
    "X_test=X[indices[number_of_training_examples:]]\n",
    "Y_test=Y[indices[number_of_training_examples:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train) \n",
    "knn.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En enkel måte å redusere dimensjonene til et problem er å droppe de minst viktige attributtene, kalt feature selection. Det er mange måter å gjøre det på. Èn måte er å fjerne alle attributter som har en varians lavere enn et gitt nivå, som i eksempelet under. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0.2)\n",
    "sel.fit(X)\n",
    "X_feature_selection = sel.transform(X)\n",
    "print(\"Hvilke attributter som var viktige nok til å få være med \" + str(sel.get_support()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gjør en PCA på datasettet ved hjelp av scikit (http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "\n",
    "Reduserer dimensjonen til X slik at den kun har 3 dimensjoner og lagre resultatet i X_pca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA-analysen i forrige oppgave skal ha gitt deg en X-matrise som nå kun består av tre features/attributter. Disse tre attributtene er ikke lik noen av de opprinnelige attributtene, men hver nye attributt er en unik kombinasjon av alle de opprinnelige attributtene. I denne oppgaven skal vi se på hvor viktig hver av egenvektorene er for å beskrive datasettet.  \n",
    "\n",
    "Hent ut en oversikt over hvor stor andel hver egenvektor har for å forklare variansen i datasettet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA-analysen i forrige oppgave skal ha gitt deg en X-matrise som nå kun består av tre features/attributter. Disse tre attributtene er ikke lik noen av de opprinnelige attributtene, men hver nye attributt er en unik kombinasjon av alle de opprinnelige attributtene. I denne oppgaven skal vi se hvordan vi kan beskrive de nye attributenne ved hjelp av de opprinnelige. \n",
    "\n",
    "Hent ut komponentene som PCA-analysen består av."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du ser nå (forhåpentligvis) på en 3x4-matrise. Hver rad beskriver en egenvektor (en ny attributt) og innholder fire elementer som representerer de opprinnelige attributene. Hvert element sier deg i hvor stor grad hver egenvektoren beskrives av de opprinnelige attributten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot resultatet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "plt.cla()\n",
    "\n",
    "for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]:\n",
    "    ax.text3D(X_pca[y == label, 0].mean(),\n",
    "              X_pca[y == label, 1].mean() + 1.5,\n",
    "              X_pca[y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "\n",
    "y = np.choose(Y, [1, 2, 0]).astype(np.float)\n",
    "\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=y, cmap=plt.cm.spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tren en klassifiseringsmodell på det dimensjonsreduserte datasettet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forventer du et bedre eller dårligere resultat enn modellen du bygget tidligere på hele datasettet? Når ønsker du å bruke PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(X))\n",
    "number_of_training_examples = int(0.8*len(X))\n",
    "\n",
    "X_PCA_train=X_pca[indices[:number_of_training_examples]]\n",
    "Y_train=Y[indices[:number_of_training_examples]]\n",
    "X_PCA_test=X_pca[indices[number_of_training_examples:]]\n",
    "Y_test=Y[indices[number_of_training_examples:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_PCA_train, Y_train) \n",
    "knn.score(X_PCA_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Erstatt PCA med Cross Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når vi reduserer dimensjonene med PCA ser vi kun på input-dataen (X), og finner de dimensjonene som beskriver datasettet best mulig slik at vi taper minst mulig informasjon når vi reduserer dimensjonene. \n",
    "\n",
    "En annen måte å redusere dimensjonene på er å ta i bruk det vi ønsker å predikere (Y) og velge de dimensjonene som beskriver Y best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "cca = CCA(n_components=4)\n",
    "cca.fit(X_train, Y_train)\n",
    "#X_train_r, Y_train_r = cca.transform(X_train, Y_train)\n",
    "#X_test_r, Y_test_r = cca.transform(X_test, Y_test)\n",
    "cca.score(X_test,Y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
