{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last ned datasett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "\n",
    "dataset_wine_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "wine = pd.read_csv(dataset_wine_url, sep=';')\n",
    "\n",
    "Y = wine.quality\n",
    "X = wine.drop('quality', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversikt over attributtene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
      "mean        8.319637          0.527821     0.270976        2.538806   \n",
      "std         1.741096          0.179060     0.194801        1.409928   \n",
      "min         4.600000          0.120000     0.000000        0.900000   \n",
      "25%         7.100000          0.390000     0.090000        1.900000   \n",
      "50%         7.900000          0.520000     0.260000        2.200000   \n",
      "75%         9.200000          0.640000     0.420000        2.600000   \n",
      "max        15.900000          1.580000     1.000000       15.500000   \n",
      "\n",
      "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
      "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
      "mean      0.087467            15.874922             46.467792     0.996747   \n",
      "std       0.047065            10.460157             32.895324     0.001887   \n",
      "min       0.012000             1.000000              6.000000     0.990070   \n",
      "25%       0.070000             7.000000             22.000000     0.995600   \n",
      "50%       0.079000            14.000000             38.000000     0.996750   \n",
      "75%       0.090000            21.000000             62.000000     0.997835   \n",
      "max       0.611000            72.000000            289.000000     1.003690   \n",
      "\n",
      "                pH    sulphates      alcohol      quality  \n",
      "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
      "mean      3.311113     0.658149    10.422983     5.636023  \n",
      "std       0.154386     0.169507     1.065668     0.807569  \n",
      "min       2.740000     0.330000     8.400000     3.000000  \n",
      "25%       3.210000     0.550000     9.500000     5.000000  \n",
      "50%       3.310000     0.620000    10.200000     6.000000  \n",
      "75%       3.400000     0.730000    11.100000     6.000000  \n",
      "max       4.010000     2.000000    14.900000     8.000000  \n"
     ]
    }
   ],
   "source": [
    "print(wine.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tren en klassifiseringsmodell på datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48125000000000001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(0)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=Y)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train) \n",
    "knn.score(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En enkel måte å redusere dimensjonene til et problem er å droppe de minst viktige attributtene, kalt feature selection. Det er mange måter å gjøre det på. Èn måte er å fjerne alle attributter som har en varians lavere enn et gitt nivå, som i eksempelet under. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hvilke attributter som var viktige nok til å få være med [ True False False  True False  True  True False False False  True]\n"
     ]
    }
   ],
   "source": [
    "sel = VarianceThreshold(threshold=0.2)\n",
    "sel.fit(X)\n",
    "X_feature_selection = sel.transform(X)\n",
    "print(\"Hvilke attributter som var viktige nok til å få være med \" + str(sel.get_support()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hva er fordelen med å redusere dimensjonene med PCA fremfor på denne måten?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gjør en PCA på datasettet ved hjelp av scikit (http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "\n",
    "Reduserer dimensjonen til X slik at den kun har 3 dimensjoner og lagre resultatet i X_pca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA-analysen i forrige oppgave skal ha gitt deg en X-matrise som nå kun består av tre features/attributter. Disse tre attributtene er ikke lik noen av de opprinnelige attributtene, men hver nye attributt er en unik kombinasjon av alle de opprinnelige attributtene. I denne oppgaven skal vi se på hvor viktig hver av egenvektorene er for å beskrive datasettet.  \n",
    "\n",
    "Hent ut en oversikt over hvor stor andel hver egenvektor har for å forklare variansen i datasettet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.94657698,  0.0483683 ,  0.00258917])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA-analysen i forrige oppgave skal ha gitt deg en X-matrise som nå kun består av tre features/attributter. Disse tre attributtene er ikke lik noen av de opprinnelige attributtene, men hver nye attributt er en unik kombinasjon av alle de opprinnelige attributtene. I denne oppgaven skal vi se hvordan vi kan beskrive de nye attributenne ved hjelp av de opprinnelige. \n",
    "\n",
    "Hent ut komponentene som PCA-analysen består av."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.13247431e-03,   3.84465551e-04,   1.70902595e-04,\n",
       "          8.64894648e-03,   6.37307290e-05,   2.18857434e-01,\n",
       "          9.75678369e-01,   3.72498542e-06,  -2.68008619e-04,\n",
       "          2.23381730e-04,  -6.35846721e-03],\n",
       "       [ -2.38994985e-02,  -2.00966661e-03,  -3.03480788e-03,\n",
       "          1.11348551e-02,  -2.36654751e-04,   9.75265982e-01,\n",
       "         -2.18916841e-01,  -2.49998510e-05,   3.27182194e-03,\n",
       "          6.18926046e-04,   1.45642451e-02],\n",
       "       [  9.53135980e-01,  -2.51315387e-02,   7.37082746e-02,\n",
       "          2.80913620e-01,   2.94578815e-03,   2.08968395e-02,\n",
       "         -1.52685886e-03,   7.76139600e-04,  -5.86305467e-02,\n",
       "          1.75252442e-02,  -4.85991164e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du ser nå (forhåpentligvis) på en 3x4-matrise. Hver rad beskriver en egenvektor (en ny attributt) og innholder fire elementer som representerer de opprinnelige attributene. Hvert element sier deg i hvor stor grad hver egenvektoren beskrives av de opprinnelige attributten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot resultatet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "plt.cla()\n",
    "\n",
    "for name, label in [('3', 3), ('4', 4), ('5', 5),  ('6', 6),  ('7', 7),  ('8', 8)]:\n",
    "    ax.text3D(X_pca[Y == label, 0].mean(),\n",
    "              X_pca[Y == label, 1].mean() + 1.5,\n",
    "              X_pca[Y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=Y, cmap=plt.cm.spectral,\n",
    "           edgecolor='k')\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tren en klassifiseringsmodell på det dimensjonsreduserte datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50312500000000004"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(0)\n",
    "indices = np.random.permutation(len(X))\n",
    "number_of_training_examples = int(0.8*len(X))\n",
    "\n",
    "X_PCA_train=X_pca[indices[:number_of_training_examples]]\n",
    "Y_train=Y[indices[:number_of_training_examples]]\n",
    "X_PCA_test=X_pca[indices[number_of_training_examples:]]\n",
    "Y_test=Y[indices[number_of_training_examples:]]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_PCA_train, Y_train) \n",
    "knn.score(X_PCA_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forventet du et bedre eller dårligere resultat enn modellen du bygget tidligere på hele datasettet? Når ønsker du å bruke PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Erstatt PCA med Cross Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når vi reduserer dimensjonene med PCA ser vi kun på input-dataen (X), og finner de dimensjonene som beskriver datasettet best mulig slik at vi taper minst mulig informasjon når vi reduserer dimensjonene. \n",
    "\n",
    "En annen måte å redusere dimensjonene på er å ta i bruk det vi ønsker å predikere (Y) og velge de dimensjonene som beskriver Y best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Din kode her"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
